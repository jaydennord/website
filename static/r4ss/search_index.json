[
["index.html", "R for Simulation Studies Preface", " R for Simulation Studies Jayden Nord Preface Published with bookdown. View book source code or make suggestions at the GitHub repository. This work is licensed under the Creative Commons Attribution 4.0 International license. "],
["intro.html", "1 Introduction 1.1 Statistics review 1.2 Simulation studies 1.3 R", " 1 Introduction 1.1 Statistics review A random variable is a variable that can assume various (typically numerical) outcomes subject to a random process. The probabilities of these outcomes are described by a probability distribution. Random variables and their distributions are described and defined by parameters, generically denoted as \\(\\theta\\) for one parameter or \\(\\vec{\\theta} = \\theta_1, \\dots, \\theta_p\\) for a collection of parameters. At any time, values of the random variable can be recorded; such recordings are called observations or random variates. Random variables tend to be denoted with upper-case letters (e.g. \\(X\\)) while observations tend to be denoted with lower-case letters (e.g. \\(x\\)). A random sample is a collection of \\(n\\) random variables that are identically and independently distributed (iid). In this text, random samples will be denoted with vector notation such as \\(\\vec{X} = X_1, \\dots, X_n\\). The observed sample is the collection of observed values of a random sample, \\(\\vec{x} = x_1, \\dots, x_n\\). A statistic is a function of the random sample and is itself a random variable. An estimator is a statistic intended to estimate some parameter \\(\\theta\\) and may be denoted as \\(W(\\vec{X})=W\\). Because an estimator is also a statistic, it is a random variable. An estimate is an observation of \\(W\\) and is a numerical outcome of \\(W(\\vec{x})=w\\); it is a function of the observed sample. Properties of some estimator \\(W\\) of \\(\\theta\\) are important for statistical inference. Ideally, \\(W\\) is accurate and precise or \\(\\mathrm{E}W-\\theta\\) is small (accuracy) and \\(\\mathrm{Var}W\\) is small (precision). The expression \\(W-\\theta\\) is referred to as error and its expectation \\(\\mathrm{E}\\left(W-\\theta\\right) = \\mathrm{E}W-\\theta\\) is referred to as bias. The expectation of squared errors or mean squared error (MSE) is expressed as \\(\\mathrm{E}\\left[\\left(W-\\theta\\right)^2\\right]\\). Mathematical proofs will show that MSE can also be expressed as \\(\\mathrm{Var}W + \\mathrm{Bias}^2W\\). That is, MSE contains information about the precision and accuracy of \\(W\\). If \\(W\\) is unbiased, \\(\\mathrm{E}W=\\theta\\), then \\(\\mathrm{MSE}(W)=\\mathrm{Var}W\\). Ratios of MSEs are often used to compare estimators. In some cases, we can derive the distribution of \\(W\\), the sampling distribution, and use its properties to analytically calculate \\(E(W)\\) and \\(Var(W)\\) and thus and bias and MSE. For example, consider the sample mean of a random sample from the normal distribution. Let \\(X_1, \\dots, X_n\\) be iid normal with some mean \\(\\mu\\) and some variance \\(\\sigma^2\\). That is, \\(X_i \\sim N(\\mu, \\sigma^2)\\). The sample mean is calculated as \\(\\bar{X} = n^{-1}\\sum^n_{i=1}{X_i}\\) and is an estimator of \\(\\mu\\). It is known that \\(\\bar{X} \\sim N(\\mu, n^{-1}\\sigma^2)\\). \\(\\mathrm{Bias}(\\bar{X})=\\mathrm{E}\\left(\\bar{X} - \\mu\\right) = \\mathrm{E}\\bar{X} - \\mu = \\mu-\\mu=0\\), so \\(\\bar{X}\\) is an unbiased estimator of \\(\\mu\\). Thus, \\(\\mathrm{MSE}(W) = \\mathrm{Var}W = n^{-1}\\sigma^2\\). The variance of \\(W\\) decreases as \\(n\\) increases; the precision of \\(\\bar{X}\\) as an estimator of \\(\\mu\\) improves with larger sample sizes. 1.2 Simulation studies Analytical approaches such as above are not always possible. The sampling distribution of \\(W\\) may not be available or the necessary mathematical operations are untenable. Suppose, however, that we have a random sample of iid estimators \\(W_1, \\dots, W_m\\), the distribution of \\(W_i\\) is unknown, and \\(m\\) is the total numbre of replications while \\(i\\) is an index for a replication. Furthermore, we have observations of the random sample \\(w_1, \\dots, w_m\\). The sample mean \\(\\bar{w}\\) of \\(w_1, \\dots, w_m\\) is an estimate of \\(\\mathrm{E}W\\) and the sample variance \\(s^2_W\\) is an estimate of \\(\\mathrm{Var}W\\). As \\(m\\) increases, the quality of the estimates improves. Each \\(w_i\\) is the result of \\(W(\\mathbf{d}_i)\\) where \\(\\mathbf{d}_i\\) is an observed sample or dataset. The observed data could be a single variable or a collection of variables presumed to follow a model and distribution with some parameters \\(\\vec{\\theta}\\). The parameters could be distribution parameters (mean, variance), regression coefficients, or some other statistic that defines the model. In applied statistics, we are interested in estimating and making inferences about some parameter \\(\\theta\\). Usually, only one replication of \\(n\\) cases is gathered from the population and the analyst supposes a model to estimate \\(\\theta\\). It is assumed that the observed data are the realized values of random samples from a defined distribution or model. The analyst then makes inferences about the population using estimates of \\(\\theta\\). In simulation studies, we are interested in the properties of some \\(W\\) that is an estimator of \\(\\theta\\). 1.3 R "],
["r-essentials-intro.html", "2 Introduction 2.1 Readings 2.2 Focus 2.3 Exercises", " 2 Introduction This section is a curation of resources for learning R. Readings are primarily sourced from the following texts: An Introduction to R by Venables, Smith, and the R Core Team. Abbreviated as “intro-r”. PDF download here. R Language Definition by the R Core Team. Abbreviated as “rldef”. PDF download here. Advanced R by Hadley Wickham. Abbreviated as “adv-r”. R for Data Science by Grolemund and Wickham. Abbreviated as “r4ds”. In each R essentials chapter, including this chapter, there is a list of readings. Then there is a focus section that outlines important concepts to be gained from the readings. At the end of each chapter, exercises are (usually) provided. When I feel that the curated readings are insufficient, I will provide additional text within the chapters. 2.1 Readings Primary readings intro-r - 1 - Introduction skip 1.2 through 1.6 r4ds - 4 - Workflow: basics r4ds - 6 - Workflow: scripts r4ds - 8 - Workflow: projects rldef - 3.2 Control structures skip subsections Hadley Wickham’s style guide Google’s R style guide Secondary readings adv-r - 3 - Names and values Vocabulary from Advanced R - 1st Edition adv-r - 26 - Optimising code 2.2 Focus The primary readings should be read and the secondary readings are only encouraged. The primary readings are to help you learn how to use R and RStudio at their most basic level. Style guides are provided so as to learn how to write code in a readable manner. The secondary readings are provided as exposure; they contain concepts that may not be understandable if you have not used R extensively. The secondary readings should be revisited occasionally as your R knowledge base grows. 2.3 Exercises None. "],
["data-structures-and-operations.html", "3 Data structures and operations 3.1 Readings 3.2 Focus 3.3 Matrices 3.4 Exercises", " 3 Data structures and operations 3.1 Readings intro-r - 2 - Simple manipulations; numbers and vectors skip 2.7 intro-r - 3 - Objects, their modes and attributes adv-r - 4 - Vectors here - Matrices r4ds - 20 - Vectors skip 20.4.5, 20.7.2 20.7.3 not required 3.2 Focus Vectors definition of a vector difference between atomic and recursive vectors (i.e. lists) the three common types of atomic vectors (logical, numeric, character) creating vectors using c(), rep(), seq(), and friends definition of a factor math and logic vectorized operations; understand recycling math and logic summary operations paste() and paste0() implicit and explicit coercion Matrices definition of a matrix difference between vectors and matrices creating matrices efficiently fundamental matrix math and algebra functions; understand recycling binding and concatenation results of length(), nrow(), and ncol() and why Data frames relationship between a data.frame and a… list matrix creating data frames from scratch or by coercion binding and concatenation preventing coercion of components to factor and why we would want to prevent such a coercion results of length(), nrow(), and ncol() and why All attributes, primarily names; getting and setting names of elements/components/dimensions missing values; the default type of NA 3.3 Matrices Arrays are data structures with two or more dimensions; two or more index values are required to identify a specific element. A matrix is an array with only two dimensions. In R, an array is technically a vector with additional dimension attributes. 3.3.1 Matrix creation There are many ways to create matrices and arrays (see here), but we will focus on the matrix function, which has the following arguments: data nrow ncol byrow dimnames The data argument is required and is typically a vector (atomic or not). If nrow and ncol are not provided, data is made into a one-column matrix. If only one of nrow and ncol are provided, then the other is calculated as length(data) divided by the given. If the result is not an integer, the result is rounded, a warning message is issued, and recycling rules are invoked (see next chapter) to fill the matrix. The arguments nrow and ncol define the matrix dimensions. By default, values of data fill the matrix column-wise. That is, columns are filled top-down before the next column is filled. For example, matrix(1:9, ncol = 3) #&gt; [,1] [,2] [,3] #&gt; [1,] 1 4 7 #&gt; [2,] 2 5 8 #&gt; [3,] 3 6 9 The number of rows (nrow) was determined by the length of 1:9 being divided by ncol. The vector 1:9 then filled the \\(3 \\times 3\\) matrix by column. Filling by column is the default behavior of matrix because byrow = FALSE by default. Using byrow = TRUE fills by row. matrix(1:9, ncol = 3, byrow = TRUE) #&gt; [,1] [,2] [,3] #&gt; [1,] 1 2 3 #&gt; [2,] 4 5 6 #&gt; [3,] 7 8 9 A consequence of c is that dimensions (and all other attributes except names) are removed from the arguments. Thus, using c on a matrix can be used to transform the matrix into a vector. The resulting vector from c on a matrix is assembled by column. There is no optional argument of c such that the vector is assembled by row. x &lt;- matrix(1:9, ncol = 3) c(x) #&gt; [1] 1 2 3 4 5 6 7 8 9 y &lt;- matrix(1:9, ncol = 3, byrow = TRUE) c(y) #&gt; [1] 1 4 7 2 5 8 3 6 9 We can see how a matrix has both a dim attribute and a class, which should not be confused with the matrix’s data type. x &lt;- matrix(1:9, ncol = 3) attributes(x) #&gt; $dim #&gt; [1] 3 3 class(x) #&gt; [1] &quot;matrix&quot; typeof(x) #&gt; [1] &quot;integer&quot; 3.3.2 Dimensions and length [INCOMPLETE] 3.3.3 Dimnames and names [INCOMPLETE] x &lt;- matrix(1:4, nrow = 2, dimnames = list(c(&quot;r1&quot;, &quot;r2&quot;), c(&quot;c1&quot;, &quot;c2&quot;))) print(x) #&gt; c1 c2 #&gt; r1 1 3 #&gt; r2 2 4 y &lt;- matrix(1:4, nrow = 2) rownames(y) &lt;- c(&quot;r1&quot;, &quot;r2&quot;) colnames(y) &lt;- c(&quot;c1&quot;, &quot;c2&quot;) print(y) #&gt; c1 c2 #&gt; r1 1 3 #&gt; r2 2 4 z &lt;- matrix(1:4, nrow = 2, dimnames = list(NULL, c(&quot;c1&quot;, &quot;c2&quot;))) print(z) #&gt; c1 c2 #&gt; [1,] 1 3 #&gt; [2,] 2 4 3.3.4 Matrix binding Because c removes the dimensions attribute, it cannot be used to concatenate matrices. Furthermore, c does not specify the dimensions along which the concatenation is supposed to occur. To concatenate two or more matrices together, the cbind and rbind functions are used. cbind is used to bind columns while rbind is used to bind rows. Arguments of cbind must have the same number of rows while arguments of rbind have the same number of columns. x &lt;- matrix(1:4, nrow = 2) y &lt;- matrix(5:8, nrow = 2) cbind(x, y) #&gt; [,1] [,2] [,3] [,4] #&gt; [1,] 1 3 5 7 #&gt; [2,] 2 4 6 8 rbind(x, y) #&gt; [,1] [,2] #&gt; [1,] 1 3 #&gt; [2,] 2 4 #&gt; [3,] 5 7 #&gt; [4,] 6 8 If the arguments are vectors, the binding function will automatically turn the vectors into matrices. cbind turns vectors into one-column matrices while rbind turns vectors into one-row matrices. Binding will also use argument or object names as dimension names for the vector. x &lt;- y &lt;- 1:3 cbind(1:3) #&gt; [,1] #&gt; [1,] 1 #&gt; [2,] 2 #&gt; [3,] 3 rbind(1:3) #&gt; [,1] [,2] [,3] #&gt; [1,] 1 2 3 cbind(x, y) #&gt; x y #&gt; [1,] 1 1 #&gt; [2,] 2 2 #&gt; [3,] 3 3 cbind(x = 1:3, y = 1:3) #&gt; x y #&gt; [1,] 1 1 #&gt; [2,] 2 2 #&gt; [3,] 3 3 z &lt;- matrix(1:6, nrow = 3, dimnames = list(NULL, c(&quot;z1&quot;, &quot;z2&quot;))) cbind(z, x = 1:3) #&gt; z1 z2 x #&gt; [1,] 1 4 1 #&gt; [2,] 2 5 2 #&gt; [3,] 3 6 3 3.3.5 Matrix coercion The implicit coercion hiearchy applies to matrices. x &lt;- matrix(1:4, ncol = 2) typeof(x) #&gt; [1] &quot;integer&quot; y &lt;- x * .5 typeof(y) #&gt; [1] &quot;double&quot; lettered_mat &lt;- matrix(c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;), ncol = 2) z &lt;- cbind(x, lettered_mat) print(z) #&gt; [,1] [,2] [,3] [,4] #&gt; [1,] &quot;1&quot; &quot;3&quot; &quot;a&quot; &quot;c&quot; #&gt; [2,] &quot;2&quot; &quot;4&quot; &quot;b&quot; &quot;d&quot; typeof(z) #&gt; [1] &quot;character&quot; Using explicit coercion functions (i.e. as.###) will remove the dimensions attribute from the matrix, creating a vector. Using mode&lt;-, however, will maintain dimensions because mode&lt;- only changes the data type, leaving the dimension attribute untouched. x &lt;- matrix(1:4, ncol = 2) as.character(x) #&gt; [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; mode(x) &lt;- &quot;character&quot; print(x) #&gt; [,1] [,2] #&gt; [1,] &quot;1&quot; &quot;3&quot; #&gt; [2,] &quot;2&quot; &quot;4&quot; 3.3.6 Matrix operations * does not invoke matrix multiplication. This is sensible because * is a vectorized operator; matrix elements are multiplied together as if their underlying vectors were cross-multiplied. For matrix multiplication, the operator %*% is used instead. x &lt;- matrix(1:9, nrow = 3) y &lt;- matrix(9:1, nrow = 3) x * y #&gt; [,1] [,2] [,3] #&gt; [1,] 9 24 21 #&gt; [2,] 16 25 16 #&gt; [3,] 21 24 9 x %*% y #&gt; [,1] [,2] [,3] #&gt; [1,] 90 54 18 #&gt; [2,] 114 69 24 #&gt; [3,] 138 84 30 Other useful functions related to matrices. function description var, cov Compute the covariance matrix of some input matrix t transpose solve inverse of a square matrix. Can also solve a system of linear equations if a second argument is provided det find determinant of a matrix eigen find eigenvalues and eigenvectors of a matrix chol performs a Cholesky decomposition on a matrix - useful for multivariate data generation diag is another matrix-related though frustrating function because its behavior and results change depending on the input. The table below describes the different results of some object x. Input Output x is numeric and length 1 An \\(x\\times x\\) identity matrix x is numeric and length = \\(y&gt;1\\) A \\(y\\times y\\) matrix with diagonal elements equal to x and off-diagonals equal to 0. x is a square matrix Atomic vector whose elements are the diagonals of x For example, diag(3) #&gt; [,1] [,2] [,3] #&gt; [1,] 1 0 0 #&gt; [2,] 0 1 0 #&gt; [3,] 0 0 1 diag(4:6) #&gt; [,1] [,2] [,3] #&gt; [1,] 4 0 0 #&gt; [2,] 0 5 0 #&gt; [3,] 0 0 6 diag(matrix(1:9, nrow = 3)) #&gt; [1] 1 5 9 diag&lt;- can also be used to overwrite the diagonal of a matrix. x &lt;- matrix(.5, nrow = 3, ncol = 3) x #&gt; [,1] [,2] [,3] #&gt; [1,] 0.5 0.5 0.5 #&gt; [2,] 0.5 0.5 0.5 #&gt; [3,] 0.5 0.5 0.5 diag(x) &lt;- rep(1, 3) x #&gt; [,1] [,2] [,3] #&gt; [1,] 1.0 0.5 0.5 #&gt; [2,] 0.5 1.0 0.5 #&gt; [3,] 0.5 0.5 1.0 Occassionally, we must find sums/means of rows or sums/means of columns of a matrix. The mean() and sum() functions will not work because they ignore the dimensions and matrix class of their input; they only work on atomic vectors. Though looping procedures can accomplish these row and column operations, fast efficient functions exist for these tasks. rowSums rowMeans colSums colMeans x &lt;- matrix(1:9, nrow = 3) rowSums(x) #&gt; [1] 12 15 18 rowMeans(x) #&gt; [1] 4 5 6 colSums(x) #&gt; [1] 6 15 24 colMeans(x) #&gt; [1] 2 5 8 3.4 Exercises What will be the data type of the following vectors? Why? c(0, 4, &quot;2&quot;) c(1:4, NA_real_) c(1:4, NA) -7:1 * 2L -7:1 * 2 Consider the following code block. x &lt;- &quot;First line here. Second line here.&quot; cat(x) #&gt; First line here. #&gt; Second line here. The author intended the “Second line here” to be printed with no indentation. Why was indentation produced? Using the followving vectors, a &lt;- c(3, 4, 8, 9) b &lt;- c(2, 7, 5, 6) c &lt;- c(3, 9, 1, 2) create a \\(4\\times 3\\) matrix in two ways. Include column names without the use of colnames() with c() and matrix() with cbind() The creation of x in the following codeblock is tedious. x &lt;- c( 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5 ) x &lt;- matrix(x, nrow = 5, byrow = TRUE) Recreate x using sequences, rep(), and two different approaches: with byrow = FALSE with byrow = TRUE Each approach should be written with only one line of code. Given x &lt;- c(&quot;300 mg&quot;, &quot;500 mg&quot;, &quot;200 mg&quot;), create a factor such that the values will sort in “descending” order. Include 100 and 400 mg as possible levels. Given x, use vectorized operations to determine which elements of x are less than or equal to 95 and greater than or equal to 75. The result should be a logical vector. x &lt;- c( 82, 82, 94, 67, 79, 68, 74, 103, 61, 70, 74, 70, 69, 63, 70 ) In the following code block, a user wanted to create a logical vector specifying which elements were equal to one or two. The results are not what the user intended. What is the mistake and what caused it? How would you correct the mistake? (Note: there are at least three ways) x &lt;- c(1, 2, 1, 1, 3, 3, 2, 1, 0, 0) x == c(1, 2) #&gt; [1] TRUE TRUE TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE A user has a matrix x defined below. The user intended to multiply the first column by three and the second column by two. The results are not what the user intended. x &lt;- matrix(1:6, ncol = 2) x #&gt; [,1] [,2] #&gt; [1,] 1 4 #&gt; [2,] 2 5 #&gt; [3,] 3 6 x * c(3, 2) #&gt; [,1] [,2] #&gt; [1,] 3 8 #&gt; [2,] 4 15 #&gt; [3,] 9 12 What is the mistake and what caused it? Correct the mistake using three approaches: Using t() without rep() Using rep() without t() Using %*% "],
["indexing.html", "4 Indexing 4.1 Readings 4.2 Focus 4.3 Exercises", " 4 Indexing I will refer to indexing as the act of subsetting, accessing, or modifying elements, components, or parts of an object. Indexing is critical for manipulating or accessing parts of objects. 4.1 Readings adv-r - 5 - Subsetting 5.5 not required 4.2 Focus Four main types of indexing and how to use logical positive integer negative integer name Three indexing operators and the differences among them [ [[ $ Using indices to… subset arrange modify-in-place 4.3 Exercises Let x &lt;- matrix(1:16, nrow = 4) y &lt;- matrix(1:12, nrow = 4) Using indexes, cross-multiply the second row of x and the third column of y. What is the sum of the resulting vector? "],
["control-structures.html", "5 Control structures 5.1 Readings 5.2 Focus 5.3 ifelse() part 1 5.4 Exercises", " 5 Control structures If-else statements and for-loops are ubiquitous among all programming languages. If-else statements allow different pieces of code to be ran if different conditions are fulfilled. For-loops allow us to repeat lines of code that would otherwise be copy-and-pasted. If you have learned these control structures in another language, it should be straightforward to learn them in R. If you learn these control structures first in R, it should be straightforward to learn them in other languages. 5.1 Readings intro-r - 9 - Grouping, loops, and conditional execution rldef - 3.2 - Control structures here - ifelse() part 1 r4ds - 21 - Iteration Only 21.1 through 21.3 5.2 Focus What ; or { do if-else statements when and how to use if-else statements how if-else statements or chains are evaluated difference between if-else statements and ifelse() for-loops when and how to use a for-loop pre-allocation 5.3 ifelse() part 1 Although not strictly a “control structure”, the ifelse() function must be discussed here so as to not confuse it with if-else statements. The ifelse() function is a vectorized version of if-else statements applied to each element of a vector. The function has three arguments: test, yes, and no. test is a logical vector and for each instance of TRUE, the same positioned element from yes is used in the result. For each instance of FALSE in test, the same poisitioned element from no is used in the result. With x defined below, we declare values that are less than 5 as NA. Furthermore, we arbitrarily square elements that are greater than or equal to 5. First, a naive approach using for-loops and if-else statements is used. Then, a ifelse() approach is demonstrated. Naive approach: x &lt;- c( 7.973, 4.885, 2.676, 3.075, 7.701, 5.363, 4.798, -0.406, 5.814, 5.682 ) z &lt;- numeric(length(x)) for (i in seq_along(x)) { if (x[i] &lt; 5) { z[i] &lt;- NA } else { z[i] &lt;- x[i]^2 } } print(z) #&gt; [1] 63.56873 NA NA NA 59.30540 28.76177 NA #&gt; [8] NA 33.80260 32.28512 ifelse() approach: x &lt;- c( 7.973, 4.885, 2.676, 3.075, 7.701, 5.363, 4.798, -0.406, 5.814, 5.682 ) z &lt;- ifelse(x &lt; 5, NA, x^2) print(z) #&gt; [1] 63.56873 NA NA NA 59.30540 28.76177 NA #&gt; [8] NA 33.80260 32.28512 The following table may help illustrate how ifelse() works. data.frame(x = x, test = x &lt; 5, yes = NA, no = x^2, result = z) #&gt; x test yes no result #&gt; 1 7.973 FALSE NA 63.568729 63.56873 #&gt; 2 4.885 TRUE NA 23.863225 NA #&gt; 3 2.676 TRUE NA 7.160976 NA #&gt; 4 3.075 TRUE NA 9.455625 NA #&gt; 5 7.701 FALSE NA 59.305401 59.30540 #&gt; 6 5.363 FALSE NA 28.761769 28.76177 #&gt; 7 4.798 TRUE NA 23.020804 NA #&gt; 8 -0.406 TRUE NA 0.164836 NA #&gt; 9 5.814 FALSE NA 33.802596 33.80260 #&gt; 10 5.682 FALSE NA 32.285124 32.28512 A heinous abuse of ifelse() sometimes occurs when one does not understand the difference between ifelse() and if-else statements. x &lt;- c( 7.973, 4.885, 2.676, 3.075, 7.701, 5.363, 4.798, -0.406, 5.814, 5.682 ) z &lt;- numeric(length(x)) for (i in seq_along(x)) { ifelse(x[i] &lt; 5, z[i] &lt;- NA, z[i] &lt;- x[i]^2) } print(z) #&gt; [1] 63.56873 NA NA NA 59.30540 28.76177 NA #&gt; [8] NA 33.80260 32.28512 Understanding this travesty may require understanding of lazy-evaluation. Lazy-evaluation refers to the fact that functions only evaluate arguments when those arguments are needed. For each ith iteration, x[i] &lt; 5 is tested. If the test is true, z[i] &lt;- NA is used. Because the test is length one, z[i] &lt;- NA executes, using or evaluating only yes and ignoring no. The argument yes, however, is also an assignment. When an assignment is also an argument, the assignment occurs and the value of the assignment is used as the argument. The result of ifelse(), however, is discarded, and z[i] is only populated as a side-effect of the assignment-within-argument. A similar outcome occurs if x[i] &lt; 5 is false. Essentially, the use of ifelse() was wasted. 5.4 Exercises The if-else statements below are resulting in an error. What is the cause of the error and how should it be fixed? x &lt;- &quot;1&quot; if (is.numeric(x)) { print(&quot;this is a number&quot;) } else { #&gt; Error: unexpected &#39;else&#39; in &quot;else&quot; print(&quot;this is not a number&quot;) #&gt; [1] &quot;this is not a number&quot; } #&gt; Error: unexpected &#39;}&#39; in &quot;}&quot; Use for-loops to mimic colMeans and rowMeans for the following matrix x &lt;- matrix(c( 9, 4, 3, 10, 7, 4, 2, 15, 0, 1, 3, 19 ), nrow = 3, byrow = TRUE) a &lt;- colMeans(x) b &lt;- rowMeans(x) Consider two vectors and their product x &lt;- c(5, 4, 3, 9, 1) y &lt;- c(2, 4) z &lt;- x * y #&gt; Warning in x * y: longer object length is not a multiple of shorter object #&gt; length z #&gt; [1] 10 16 6 36 2 Write a short script that uses a for-loop to mimic z &lt;- x * y. Hint: See ?rep for other useful repeater functions. "],
["functions.html", "6 Functions 6.1 Readings 6.2 Focus 6.3 ifelse() part 2 6.4 Exercises", " 6 Functions 6.1 Readings r4ds - 19 - Functions skip 19.6.2 adv-r - 6 - Functions adv-r - 9 - Conditions here - ifelse() part 2 R Packages: A Beginner’s Guide by Adolfo Alvarez 6.2 Focus purpose of functions how to write a function; basic anatomy: arguments, body default arguments dot-dot-dot (...) argument conditions: errors and warnings lexical scoping special functions infix replacement how to use do.call() packages installation, loading function conflicts 6.3 ifelse() part 2 In the previous chapter, an inappropriate use of ifelse() was demonstrated. The success of this inappropriate use depended on lazy evaluation. With newfound knowledge of function creation, we can further explore this issue. Previously, x &lt;- c( 7.973, 4.885, 2.676, 3.075, 7.701, 5.363, 4.798, -0.406, 5.814, 5.682 ) z &lt;- numeric(length(x)) for (i in seq_along(x)) { ifelse(x[i] &lt; 5, z[i] &lt;- NA, z[i] &lt;- x[i]^2) } print(z) #&gt; [1] 63.56873 NA NA NA 59.30540 28.76177 NA #&gt; [8] NA 33.80260 32.28512 Consider the case when i == 2. The test x[2] &lt; 5 resolves to TRUE and the argument z[2] &lt;- NA will be used. As a side-effect, the assignment z[2] &lt;- NA resolves. The argument z[2] &lt;- x[2]^2 is never used, so it never executes. Such is the consequence of lazy evaluation. We can, however, force arguments to evaluate non-lazily using force(). In the following code block, a new function ifelse2() is defined that forces the evaluation of all arguments. x &lt;- c( 7.973, 4.885, 2.676, 3.075, 7.701, 5.363, 4.798, -0.406, 5.814, 5.682 ) ifelse2 &lt;- function(...){ for(x in list(...)) force(x) ifelse(...) } z2 &lt;- numeric(length(x)) for (i in seq_along(x)) { ifelse2(x[i] &lt; 5, z2[i] &lt;- NA, z2[i] &lt;- x[i]^2) } print(z2) #&gt; [1] 63.568729 23.863225 7.160976 9.455625 59.305401 28.761769 23.020804 #&gt; [8] 0.164836 33.802596 32.285124 Again, the true result of ifelse2() and by extension ifelse() was never captured. The arguments, however, were evaluated in order. Thus, for all cases where x[i] &lt; 5 == TRUE, z2[i] &lt;- NA will occur, but then z2[i] &lt;- x[i]^2 will override the previous assignment. This should reinforce the idea that the inappropriate use of ifelse() was only successful because of lazy evaluation, not because the function was used as intended. Note that ifelse2() performs the same as ifelse() if used correctly. x &lt;- c( 7.973, 4.885, 2.676, 3.075, 7.701, 5.363, 4.798, -0.406, 5.814, 5.682 ) ifelse2(x &lt; 5, NA, x^2) #&gt; [1] 63.56873 NA NA NA 59.30540 28.76177 NA #&gt; [8] NA 33.80260 32.28512 6.4 Exercises Consider the following code block involving matrix multiplication. a &lt;- matrix(1:4, ncol = 2) b &lt;- matrix(c(5, 3, 8, 9, 3, 4), ncol = 2) a %*% b #&gt; Error in a %*% b: non-conformable arguments b %*% a #&gt; [,1] [,2] #&gt; [1,] 23 51 #&gt; [2,] 9 21 #&gt; [3,] 16 40 Using for-loops, create a function mm, in functional form, to mimic %*% wihtout using %*%. Create the infix version of mm as well without copy-and-pasting any code. Consider the following code block. x &lt;- c( 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5 ) x &lt;- matrix(x, nrow = 5, byrow = TRUE) Recreate x using rep, list, do.call, and cbind. Note that this is strictly an exercise and not an example of how to create matrices like x in practice. "],
["functionals.html", "7 Functionals 7.1 Readings 7.2 Focus 7.3 Exercises", " 7 Functionals Functionals are functions that take other functions as input and return some vector as output. Some of the most important functionals are looping functionals - efficient and clearer substitutes for for-loops. 7.1 Readings adv-r - 11 - Functionals skip 11.3.3, 11.3.4, 11.4.1, and 11.4.3 r4ds - 21 - Iteration 21.4 through 21.9 Why use purrr::map instead of lapply? discussion on stackoverflow.com 7.2 Focus definition of functional how to use looping functionals: apply family: lapply(), sapply(), vapply(), mapply(), Map() repetitious functionals: Reduce(), replicate() to a lesser extent, map family from tidyverse/purrr: map(), map_*(), map2(), pmap(), walk(), etc. when to use looping functionals versus for-loops the benefits of using the apply family over the map family the benefits of using the map family over the apply family 7.3 Exercises A user wanted to quickly get the standard deviations of each column of x using sapply. The results, however, are nonsensicle. Inspect the user’s code below and determine why the nonsense result occurred. How can the code be corrected to give what the user wanted? x &lt;- matrix(c( 3, 2, 9, 2, 4, 3, 4, 5, 5, 6, 3, 8 ), ncol = 3, byrow = TRUE) sapply(x, sd) #&gt; [1] NA NA NA NA NA NA NA NA NA NA NA NA Consider the following code block. x &lt;- c( 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5 ) x &lt;- matrix(x, nrow = 5, byrow = TRUE) Recreate x using sequences and replicate. Consider the following code block involving matrix multiplication. a &lt;- matrix(1:4, ncol = 2) b &lt;- matrix(c(5, 3, 8, 9, 3, 4), ncol = 2) a %*% b #&gt; Error in a %*% b: non-conformable arguments b %*% a #&gt; [,1] [,2] #&gt; [1,] 23 51 #&gt; [2,] 9 21 #&gt; [3,] 16 40 Using vapply, create a function mm to mimic %*% wihtout using %*%. Consider the following matrices already contained in a list (helpful). lst &lt;- list( a &lt;- matrix(c(5, 4, 3, 9), nrow = 2), b &lt;- matrix(c(2, 9, 1, 2), nrow = 2), c &lt;- matrix(c(3, 10, 4, 3), nrow = 2) ) Recreate lst using a functional. Use a functional or functionals to create a \\(2\\times 2\\) matrix where each element is the average of the corresponding elements in the three matrices of lst. Recreate the Map() function without using Map(), mapply(), or any function from purrr. "],
["random.html", "8 Random sampling and variate generation 8.1 Pseudo-randomness 8.2 Univariate random samples [INCOMPLETE] 8.3 Multivariate normal samples [INCOMPLETE] 8.4 Exercises", " 8 Random sampling and variate generation In the Introduction to this book. obtain sample of estimators sample depends on “sample” of randomly generated data we need to know how to randomly generate data 8.1 Pseudo-randomness Computers cannot generate truly random numbers. Instead, complex algorithms mimic randomness to produce pseudo-random numbers. These algorithms begin with an arbitrary starting value or seed that updates with each generated number. Unless otherwise specified, the seed is often based on the internal clock of the computer’s processor. The use of an algorithm makes pseudo-randomness predictable and reproducible. If one writes a program and provides a fixed value for the seed, then the program will return the same results on repeated runs. All random number generation scripts should begin with setting the seed. In R, setting the seed is accomplished with the set.seed() function that takes an arbitrary number as its argument. In the next codeblock, the runif() function is used to generate a random number between 0 and 1. Note that if you run this code in your own R session, the first instance of runif() will return a different result. When the same seed is invoked, however, the second runif() will return the same result as below. runif(n = 1) #&gt; [1] 0.4916358 set.seed(12479) runif(n = 1) #&gt; [1] 0.1121074 Pending an investigation of cyclical relationships among generated values, the seed needs to be set only once. # one run set.seed(12479) x &lt;- runif(n = 5) y &lt;- runif(n = 5) x; y #&gt; [1] 0.1121074 0.7750140 0.4247088 0.8604614 0.9952807 #&gt; [1] 0.31230762 0.06263094 0.64284741 0.59751066 0.52157322 # another run that produces the same results set.seed(12479) x &lt;- runif(n = 5) y &lt;- runif(n = 5) x; y #&gt; [1] 0.1121074 0.7750140 0.4247088 0.8604614 0.9952807 #&gt; [1] 0.31230762 0.06263094 0.64284741 0.59751066 0.52157322 Remember that the random number generation algorithm updates each time it is used to generate a value. This is illustrated below. The first run uses the random number generator to produce two random numbers with seed 12345. In the subsequent run, the seed is reset to 12345 and two separate runif() functions generate two random numbers. The values are equivalent to the first run; the same seed was used, the same generating function was used, and a random number was requested twice. # first run set.seed(12345) runif(n = 2) #&gt; [1] 0.7209039 0.8757732 # reset set.seed(12345) runif(n = 1) #&gt; [1] 0.7209039 runif(n = 1) #&gt; [1] 0.8757732 8.2 Univariate random samples [INCOMPLETE] sample() For many distributions, R provides functions for density, cumulative distribution functions, quantile functions, and random generation. These functions are of the form dxxx, pxxx, qxxx, and rxxx. We are more interested in the random generation functions rxxx. See help(Distributions) for a full list. vectorization of rxxx functions. 8.3 Multivariate normal samples [INCOMPLETE] Here, multivariate data refers to multiple non-independent random variables. There are two ways to generate data from a multivariate normal distribution. The first is to use a Cholesky decomposition and the second is to use MASS::mvrnorm(). Both approaches require a population covariance matrix. library(MASS) set.seed(12479) nobs &lt;- 1e4 # population covariance matrix Sigma &lt;- matrix(c( 3, 1, 0, 1, 5, 0, 0, 0, 10 ), nrow = 3) # Using chol() x0 &lt;- replicate(3, rnorm(nobs)) x &lt;- (x0 %*% chol(Sigma)) + rep(c(8, 3, 2), each = nobs) colMeans(x) #&gt; [1] 7.990510 2.994045 1.993155 cov(x) #&gt; [,1] [,2] [,3] #&gt; [1,] 2.92735046 0.91075099 -0.01216241 #&gt; [2,] 0.91075099 4.94800859 -0.07276899 #&gt; [3,] -0.01216241 -0.07276899 9.99723454 # Using MASS::mvrnorm() x &lt;- mvrnorm(n = nobs, mu = c(8, 3, 2), Sigma = Sigma) colMeans(x) #&gt; [1] 7.976831 2.964806 1.960594 cov(x) #&gt; [,1] [,2] [,3] #&gt; [1,] 2.90912622 1.01625027 -0.02573531 #&gt; [2,] 1.01625027 4.96394380 0.09375714 #&gt; [3,] -0.02573531 0.09375714 9.92934666 The sample covariance matrix is roughly equivalent to the population covariance matrix Sigma as expected. The sample mean vector is also roughly equivalent to the population mean vector as expected. It appears that MASS::mvrnorm is simpler than the chol method. The chol method, however, will be useful for generating normally distributed data with additional skew and kurtosis. 8.4 Exercises Use set.seed() for these exercises for reproducible results. Suppose we have \\(X_1, \\dots, X_{20}\\) such that \\(X_i \\sim Bernoulli(p_i)\\) and \\(p_i \\sim Beta(2, 3)\\). Note that the Bernoulli distribution results in 0 or 1 and the \\(p\\) parameter ranges between 0 and 1. Meanwhile, the Beta distribution ranges between 0 and 1. Generate the random sample \\(X_i, \\dots, X_{20}\\). Hint: The Bernoulli distribution is a special case of the Binomial distribution, so rbinom() may be used. Generate a random sample \\(X_1, \\dots X_{100}\\) such that \\(X_i \\sim N(10, 3)\\). Then, randomly assign data in this sample to be missing such that each case has a 5% chance of being missing. Impose missingness in three ways with: sample() rbinom() runif() Hint: Remember logical indexing. Randomly generate a sample of size 100 with three variables that have the following characteristics. \\(X\\) has variance 5, \\(Y\\) has variance 3, \\(Z\\) has variance 2, \\(X\\) and \\(Y\\) are correlated .3, and \\(Z\\) is uncorrelated with the other variables. All variables have means of 0. Confirm your generation with cov() and cor(). "],
["gen-from-lm.html", "9 Generation from linear models 9.1 Linear combination review 9.2 Exogeneity and endogeneity 9.3 General procedure 9.4 Examples 9.5 Exercises", " 9 Generation from linear models 9.1 Linear combination review This here is a vector: \\(\\underline{b}\\). It has an underline to show that it is a vector. \\(\\mathbf{\\underline{b}}\\) \\(\\underline{\\mathbf{b}}\\) Some facts about linear combinations reviewed Let \\(\\mathbf{X}\\) be a \\(n\\times p\\) matrix of \\(n\\) random samples of \\(X_1, \\dots, X_p\\). Let \\(\\mathbf{b}\\) be a \\(p \\times 1\\) vector of coefficients and let \\(\\vec{Y}\\) be a \\(n \\times 1\\) linear combination of \\(\\mathbf{X}\\) such that \\[\\vec{Y} = \\mathbf{X}\\mathbf{b}\\] Then, \\[E(Y) = E(\\mathbf{X})&#39; \\mathbf{b}\\] \\[\\text{and}\\] \\[Var(Y) = \\mathbf{b}&#39;Cov(\\mathbf{X})\\mathbf{b} = \\mathbf{\\underline{b}}&#39;\\mathbf{\\Sigma}\\mathbf{\\underline{b}}\\] Readers may be more familiar with the case of two predictors \\({X}_1\\) and \\({X}_2\\) and two coefficients \\(b_1\\) and \\(b_2\\) in which \\[E(Y) = b_1 E(X_1) + b_2 E(X_2)\\] \\[\\text{and}\\] \\[Var(Y) = b_1^2 Var(X_1) + b_2^2 Var(X_2) + 2 b_1 b_2 Cov(X_1, X_2)\\] 9.2 Exogeneity and endogeneity 9.3 General procedure 9.4 Examples 9.4.1 CRT 9.4.2 Correlated outcomes 9.4.3 Mediation 9.4.4 Multilevel 9.4.5 SEM 9.5 Exercises Consider the following correlation matrix of three predictors and a table of means, variances, and regression coefficients for the same three predictors and an outcome. \\[\\left[\\matrix{ 1 \\\\ .3 &amp; 1 \\\\ .2 &amp; .1 &amp; 1 }\\right]\\] Variable \\(\\mu\\) \\(\\sigma^2\\) \\(b\\) \\(X_1\\) 100 25 .19 \\(X_2\\) 100 30 .30 \\(X_3\\) 50 10 .22 \\(Y\\) 60 20 Generate a dataset with 100 samples using the above information as population parameters. Assume all variables are normally distributed. Consider a mediation model where \\(X\\) predicts \\(M\\) and \\(M\\) predicts \\(Y\\). The standardized effect of \\(X\\) on \\(M\\) is .3, the standardized effect of \\(M\\) on \\(Y\\) is .3, and the direct standardized effect of \\(X\\) on \\(Y\\) is .1. Two covariates, each for \\(M\\) and \\(Y\\), account for 30% of the variability of their respective outcomes. Generate 100 samples reflecting this information. Consider an SEM with latent predictors \\(\\xi_1\\) and \\(\\xi_2\\) predicting a latent outcome \\(\\eta\\). All latent variables have variance 1, the predictors are correlated .3, and the standardized effects of both predictors on \\(\\eta\\) is .3. Each latent variable has three indicators with 70% reliability. One indicator for \\(\\xi_1\\), however, has a residual correlation of .3 with an indicator from \\(\\xi_2\\). Generate 100 samples using this information and retain only the indicators in the final dataset. Generate data from a model with 10 blocks, 5 cases per block, and using the following information. A single predictor has a within-block effect of .3 on a single outcome and a between-block effect of .3 on that same outcome. The ICC for this model is .18; that is, 18% of the variance of the outcome is between-level. (exercise adapted from Natalie Koziol) Generate 100 samples using the following parameters in a mediation model. Cases are randomly assigned to one of two treatment conditions. On some outcome variable \\(M_2\\), there is a true difference in 10 units between the two treatment conditions. A covariate, \\(M_1\\) will account for 30% of the variability in \\(M_2\\). "],
["gen-mult.html", "10 Multiple replications and conditions", " 10 Multiple replications and conditions generation contained in a function for-loop, replicate() multiple generation conditions, expand.grid() "]
]
